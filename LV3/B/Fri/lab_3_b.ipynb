{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Laboratory Exercise: Bank Marketing Campaign Outcome Prediction\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this laboratory exercise, you will build a **binary classification model** that predicts whether a client will **subscribe to a term deposit** as a result of a **direct marketing campaign** conducted by a Portuguese banking institution.\n",
    "\n",
    "Each data sample represents information about a single client and their interaction with a marketing campaign (mainly phone calls). The goal is to predict the final campaign outcome based on **demographic**, **financial**, and **campaign-related** features.\n",
    "\n",
    "You will implement a **complete machine learning pipeline using PyTorch**, including data preprocessing, dataset definition, model design, training, evaluation, visualization, and final testing.\n",
    "\n",
    "This exercise focuses on **tabular data**, **mixed categorical and numerical features**, and **binary classification** using **Binary Cross-Entropy loss**.\n",
    "\n",
    "---\n",
    "\n",
    "## Problem Definition\n",
    "\n",
    "- **Task:** Binary classification\n",
    "- **Target column:** `y`\n",
    "- **Target values:**\n",
    "  - `yes` → client subscribed to a term deposit\n",
    "  - `no` → client did not subscribe\n",
    "- **Goal:** Predict whether a client will subscribe to a term deposit after the marketing campaign\n",
    "\n",
    "You will work with a provided dataset (`dataset.csv`) derived from real-world banking marketing data.\n",
    "\n",
    "---\n",
    "\n",
    "## Tasks Overview\n",
    "\n",
    "You are required to implement the following components:\n",
    "\n",
    "### 1. Data Preparation\n",
    "- Load the `dataset.csv` file\n",
    "- Identify **numerical** and **categorical** features\n",
    "- Encode categorical variables appropriately\n",
    "- Normalize or scale numerical features if needed\n",
    "- Separate features (`X`) and target (`y`)\n",
    "- Split the dataset into:\n",
    "  - Training set\n",
    "  - Validation set\n",
    "  - Test set\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Dataset Class\n",
    "- Implement a `BankMarketingDataset` class compatible with PyTorch’s `Dataset`\n",
    "- Ensure:\n",
    "  - Features are stored as `float32` tensors\n",
    "  - Targets are stored as binary labels with shape `(N, 1)`\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Model Building\n",
    "- Implement a `build_model_#` functions that returns a neural network suitable for **binary classification**\n",
    "- The models should:\n",
    "  - Accept tabular input features\n",
    "  - Use appropriate activation functions\n",
    "  - Output a single probability value (use `sigmoid` at the output layer)\n",
    "\n",
    "---\n",
    "\n",
    "### 4. Training and Evaluation\n",
    "- Implement the following functions:\n",
    "  - `train_one_epoch`\n",
    "  - `evaluate`\n",
    "  - `test`\n",
    "- Use:\n",
    "  - `BCELoss`\n",
    "- Train the model for a fixed number of epochs\n",
    "- Track:\n",
    "  - Training loss\n",
    "  - Validation loss\n",
    "  - Validation accuracy\n",
    "\n",
    "---\n",
    "\n",
    "### 5. Visualization\n",
    "- Plot the following curves:\n",
    "  - Training loss vs. epochs\n",
    "  - Validation loss vs. epochs\n",
    "  - Validation accuracy vs. epochs\n",
    "\n",
    "All plots must be clearly labeled and interpretable.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. Testing and Reporting\n",
    "- Evaluate the final trained model on the **test dataset**\n",
    "- Generate and display a **classification report**, including:\n",
    "  - Precision\n",
    "  - Recall\n",
    "  - F1-score\n",
    "  - Accuracy\n",
    "\n",
    "---\n",
    "\n",
    "## Model Comparison Requirement\n",
    "\n",
    "You must design and train **two different model configurations**, for example:\n",
    "- Different number of hidden layers\n",
    "- Different number of neurons per layer\n",
    "- Different activation functions\n",
    "- Use of dropout or other regularization techniques\n",
    "\n",
    "For **each model**, you must:\n",
    "- Train it for the same number of epochs\n",
    "- Plot training and validation metrics\n",
    "- Evaluate it on the test dataset\n",
    "- Compare the results and briefly discuss which model performs better and why"
   ],
   "id": "2a655134f9920125"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Dataset Description\n",
    "\n",
    "Each row in the dataset corresponds to one client contact and includes the following feature groups:\n",
    "\n",
    "### Client Information\n",
    "- `age` – age of the client (numeric)\n",
    "- `job` – type of job (categorical)\n",
    "- `marital` – marital status (categorical)\n",
    "- `education` – education level (categorical)\n",
    "- `default` – has credit in default? (yes/no)\n",
    "\n",
    "### Financial Information\n",
    "- `balance` – average yearly balance (numeric)\n",
    "- `housing` – has housing loan? (yes/no)\n",
    "- `loan` – has personal loan? (yes/no)\n",
    "\n",
    "### Campaign Contact Information\n",
    "- `contact` – communication type (categorical)\n",
    "- `day` – last contact day of the month (numeric)\n",
    "- `month` – last contact month (categorical)\n",
    "- `duration` – last contact duration in seconds (numeric)\n",
    "\n",
    "### Campaign History\n",
    "- `campaign` – number of contacts performed during this campaign\n",
    "- `pdays` – number of days since the client was last contacted\n",
    "- `previous` – number of contacts before this campaign\n",
    "- `poutcome` – outcome of the previous marketing campaign (categorical)\n",
    "\n",
    "### Target Variable\n",
    "- `y` – whether the client subscribed to a term deposit (`yes` / `no`)"
   ],
   "id": "7dc846eb9853272e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T12:17:26.645117Z",
     "start_time": "2025-12-19T12:17:26.640214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "2d78fb6449131e70",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-19T12:23:41.985948Z",
     "start_time": "2025-12-19T12:23:41.981431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prepare_data(df: pd.DataFrame) -> Tuple[\n",
    "    pd.DataFrame, pd.DataFrame, pd.DataFrame,\n",
    "    pd.DataFrame, pd.DataFrame, pd.DataFrame,\n",
    "    ColumnTransformer\n",
    "]:\n",
    "    \"\"\"\n",
    "    Prepare the bank marketing dataset for training and evaluation.\n",
    "\n",
    "    The input DataFrame contains demographic, financial, and campaign-related\n",
    "    information about clients contacted during a direct marketing campaign.\n",
    "    The target column `y` indicates whether the client subscribed to a term\n",
    "    deposit (`yes` or `no`).\n",
    "\n",
    "    Steps (you MUST follow these steps):\n",
    "    1. Identify feature columns and the target column `y`.\n",
    "    2. Separate features (X) and target (y).\n",
    "    3. Encode the target labels:\n",
    "       - `yes` → 1\n",
    "       - `no` → 0\n",
    "    4. Identify categorical and numerical feature columns.\n",
    "    5. Use ColumnTransformer with OneHotEncoder to encode all categorical columns:\n",
    "       - use OneHotEncoder(drop=\"first\", sparse_output=False)\n",
    "       - Pass numerical features without modification\n",
    "    6. Fit the preprocessor on the training data.\n",
    "    7. Split the data in TWO stages (keep stratification):\n",
    "       - First split into train and test:\n",
    "            * test_size = 0.2\n",
    "            * random_state = 42\n",
    "            * stratify = y\n",
    "       - Then split the training part into train and validation:\n",
    "            * test_size = 0.2   (20% of the training set)\n",
    "            * random_state = 42\n",
    "            * stratify = y_train\n",
    "    8. Return:\n",
    "         X_train, X_val, X_test, y_train, y_val, y_test, preprocessor\n",
    "\n",
    "    Notes:\n",
    "    - The returned X arrays must be fully numeric.\n",
    "    - The returned y arrays must contain binary labels with shape (N, 1) or (N,).\n",
    "    - The data must be suitable for PyTorch binary classification.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "d50c90ff40e960eb",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.297757Z",
     "start_time": "2025-12-15T20:14:53.294629Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class BankMarketingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset for bank marketing binary classification.\n",
    "\n",
    "    Each sample consists of:\n",
    "    - a numeric feature vector representing a client's profile and campaign data\n",
    "    - a binary label indicating whether the client subscribed to a term deposit\n",
    "\n",
    "    Requirements:\n",
    "    - __init__(self, X, y):\n",
    "        * X: numpy array of numeric features\n",
    "        * y: array-like of binary labels (0 or 1)\n",
    "        * Store:\n",
    "            - X as a float32 tensor\n",
    "            - y as a float32 tensor with shape (N, 1)\n",
    "    - __len__(self):\n",
    "        * Return the number of samples\n",
    "    - __getitem__(self, idx):\n",
    "        * Return (X[idx], y[idx])\n",
    "    \"\"\"\n",
    "    pass"
   ],
   "id": "33ad6ce494e276ff",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.440967Z",
     "start_time": "2025-12-15T20:14:53.438645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_one_epoch(model: nn.Module,\n",
    "                    train_loader: DataLoader,\n",
    "                    criterion,\n",
    "                    optimizer) -> float:\n",
    "    \"\"\"\n",
    "    Train the model for ONE epoch on the training dataset.\n",
    "\n",
    "    This is a binary classification task for predicting whether a client\n",
    "    subscribes to a term deposit.\n",
    "\n",
    "    Requirements:\n",
    "    - Set the model to training mode using model.train()\n",
    "    - Iterate over batches from train_loader\n",
    "    - For each batch:\n",
    "        * Compute model outputs (logits or probabilities)\n",
    "        * Compute the loss using Binary Cross-Entropy loss\n",
    "          (BCELoss or BCEWithLogitsLoss)\n",
    "        * Zero the gradients\n",
    "        * Perform backpropagation\n",
    "        * Update model parameters using the optimizer\n",
    "    - Accumulate the training loss over all batches\n",
    "    - Return the average training loss as a float\n",
    "      (total loss divided by the number of batches)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "3016b59eba365eee",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.580525Z",
     "start_time": "2025-12-15T20:14:53.578185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model: nn.Module,\n",
    "             val_loader: DataLoader,\n",
    "             criterion: nn.Module) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Evaluate the model on the validation dataset.\n",
    "\n",
    "    This is a binary classification task for bank marketing outcome prediction.\n",
    "\n",
    "    Requirements:\n",
    "    - Set the model to evaluation mode using model.eval()\n",
    "    - Disable gradient computation using torch.no_grad()\n",
    "    - Iterate over batches from val_loader\n",
    "    - For each batch:\n",
    "        * Compute model outputs\n",
    "        * Compute and accumulate validation loss\n",
    "        * Convert outputs to predicted labels using threshold 0.5\n",
    "        * Collect predicted labels and true labels\n",
    "    - Compute validation accuracy over the entire validation set\n",
    "    - Return:\n",
    "        - validation accuracy (float)\n",
    "        - validation loss (float)\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "31262b08d1b91b19",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.721259Z",
     "start_time": "2025-12-15T20:14:53.719516Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def test(model: nn.Module,\n",
    "         test_loader: DataLoader) -> tuple[Tensor, Tensor]:\n",
    "    \"\"\"\n",
    "    Evaluate the trained model on the test dataset.\n",
    "\n",
    "    This function performs inference for binary classification of\n",
    "    bank marketing campaign outcomes.\n",
    "\n",
    "    Requirements:\n",
    "    - Set the model to evaluation mode using model.eval()\n",
    "    - Disable gradient computation using torch.no_grad()\n",
    "    - Iterate over batches from test_loader\n",
    "    - For each batch:\n",
    "        * Compute model outputs\n",
    "        * Convert outputs to predicted labels using threshold 0.5\n",
    "        * Collect all predicted labels and true labels\n",
    "    - Return:\n",
    "        - Tensor of true labels (shape: N,)\n",
    "        - Tensor of predicted labels (shape: N,)\n",
    "\n",
    "    These outputs will be used to compute a classification report.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "a2b82069d52bb35a",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.857441Z",
     "start_time": "2025-12-15T20:14:53.855789Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model_1(input_dim: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Build and return a PyTorch neural network for bank marketing\n",
    "    binary classification.\n",
    "\n",
    "    Requirements:\n",
    "    - Use nn.Sequential to define the model\n",
    "    - The model must accept input vectors of size input_dim\n",
    "    - The final layer must output a single value\n",
    "    - Do NOT apply Sigmoid if using BCEWithLogitsLoss\n",
    "\n",
    "    Note:\n",
    "    - Use Binary Cross-Entropy loss during training\n",
    "    - This model will serve as the baseline architecture\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "7c371af5bc7097ec",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:53.999129Z",
     "start_time": "2025-12-15T20:14:53.997125Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def build_model_2(input_dim: int) -> nn.Module:\n",
    "    \"\"\"\n",
    "    Build and return a second PyTorch neural network for bank marketing\n",
    "    binary classification.\n",
    "\n",
    "    This model should differ from build_model_1\n",
    "    (e.g. more layers, more neurons, dropout, different activations).\n",
    "\n",
    "    Requirements:\n",
    "    - Use nn.Sequential to define the model\n",
    "    - The model must accept input vectors of size input_dim\n",
    "    - The final layer must output a single value\n",
    "    - Do NOT apply Sigmoid if using BCEWithLogitsLoss\n",
    "\n",
    "    Note:\n",
    "    - Use Binary Cross-Entropy loss during training\n",
    "    - This model will be compared against build_model_1\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ],
   "id": "bea098a0a0accc59",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Build the models",
   "id": "9c72fd94cdd4ba30"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:54.267828Z",
     "start_time": "2025-12-15T20:14:54.266001Z"
    }
   },
   "cell_type": "code",
   "source": "# Call the build functions",
   "id": "9145d1336a4f4844",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model 1",
   "id": "cda9a7bcc172faff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:54.624681Z",
     "start_time": "2025-12-15T20:14:54.622391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 0\n",
    "train_losses_1 = []\n",
    "val_losses_1 = []\n",
    "val_accuracies_1 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Call all required functions and store the computed metrics\n",
    "    # (training loss, validation loss, and validation accuracy).\n",
    "\n",
    "    train_loss =0\n",
    "    val_acc = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train loss: {train_loss:.4f} | Val acc: {val_acc:.4f}\")"
   ],
   "id": "6dafc2594240ea8b",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train model 2",
   "id": "ccbdbe9b9307d8fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:54.990662Z",
     "start_time": "2025-12-15T20:14:54.988478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 0\n",
    "train_losses_2 = []\n",
    "val_losses_2 = []\n",
    "val_accuracies_2 = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # Call all required functions and store the computed metrics\n",
    "    # (training loss, validation loss, and validation accuracy).\n",
    "\n",
    "    train_loss =0\n",
    "    val_acc = 0\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} | Train loss: {train_loss:.4f} | Val acc: {val_acc:.4f}\")"
   ],
   "id": "a372f48c2092c613",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Visualize",
   "id": "f9eac2e9cd3cf5ea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:55.416229Z",
     "start_time": "2025-12-15T20:14:55.414124Z"
    }
   },
   "cell_type": "code",
   "source": "# Visualize training and validation loss on the same plot, and visualize the validation accuracy across epochs.",
   "id": "c559c663e368e087",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Evaluate",
   "id": "3e5216ba01d97102"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-15T20:14:55.748456Z",
     "start_time": "2025-12-15T20:14:55.746530Z"
    }
   },
   "cell_type": "code",
   "source": "# Evaluate on the test dataset",
   "id": "c5b0a8ab4e73f4de",
   "outputs": [],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
